# RAG Agent Chatbot (n8n Workflow)

This workflow implements a **Retrieval-Augmented Generation (RAG) chatbot** using n8n.  
It has **two phases**:

1. **Data Ingestion** â€“ Downloads files, converts them into embeddings, and stores them in a vector database.
2. **Chat Agent** â€“ Uses the vector store to answer user questions intelligently.

---

## ğŸ“Œ Workflow Screenshot
_Add your screenshot below (replace this line with the image)._

![Workflow Screenshot](./workflow.png)

---

## ğŸ§  Overview of the Workflow

### ğŸ”¹ Phase 1 â€” Build Vector Store (Ingestion Pipeline)
This phase prepares your knowledge base.

Nodes involved:
- **Google Drive Trigger** â€“ Detects new or updated documents.
- **Download File** â€“ Fetches the document from Drive.
- **Pinecone Vector Store (Upsert)** â€“ Saves your processed text & embeddings.
- **Embedding (Google Gemini / OpenAI)** â€“ Converts document text into embeddings.
- **Various text loaders** â€“ Split or process text for vectorization.

**Purpose:**  
To index files (PDF, docs, text, etc.) and store them in Pinecone for semantic search.

---

### ğŸ”¹ Phase 2 â€” Chat Agent (RAG Retrieval + LLM Response)
This phase handles user chat queries.

Nodes involved:
- **When Chat Message Received** â€“ Chat trigger.
- **Pinecone Vector Search** â€“ Retrieves top related chunks.
- **LLM Agent (Google Gemini / OpenAI)** â€“ Generates the final answer.
- **Simplex Memory (optional)** â€“ Stores conversation history.
- **Embeddings for Query** â€“ Converts user question to embedding for semantic search.

**Purpose:**  
To answer user questions using stored knowledge + LLM reasoning.

---

## ğŸš€ How It Works

### Step 1 â€” Store Data
When a file is uploaded (Google Drive trigger):
1. File is downloaded.
2. Document text is extracted & chunked.
3. Text chunks are converted to embeddings.
4. Embeddings are stored in Pinecone.

### Step 2 â€” Answer Queries
1. User sends a chat message.
2. Message is embedded.
3. Related knowledge is retrieved from Pinecone.
4. LLM (Agent) uses context + memory to produce a final answer.

---

## ğŸ§© Requirements

### Accounts Needed
- **Google Drive**
- **Pinecone**
- **LLM provider (Gemini, OpenAI, etc.)**

### n8n Credentials
- Google Drive Credential  
- Pinecone API Credential  
- LLM Credential  
- Embeddings Credential (Gemini, OpenAI, etc.)

---

## ğŸ“ Files Included

- `workflow.json` â€“ Exported n8n workflow.
- `workflow.png` â€“ Screenshot of the workflow.

---

## â–¶ï¸ Setup Guide

1. Import `workflow.json` into n8n.
2. Configure all required credentials:
   - Google Drive
   - Pinecone
   - LLM (Gemini / OpenAI)
3. Update Pinecone:
   - Index name  
   - Namespace  
4. Test the ingestion pipeline with one sample file.
5. Open the n8n chat window and ask questions.

---

## ğŸ›  Troubleshooting

- **Vector search returns empty**  
  â†’ Check embeddings provider, index name, and namespace.

- **File not processed**  
  â†’ Verify Google Drive trigger permissions.

- **LLM does not answer correctly**  
  â†’ Increase the number of retrieved chunks (e.g., topK = 5â€“10).

- **Memory not preserved**  
  â†’ Ensure `Simplex Memory` node is connected properly.

---

## ğŸ“„ License
Free to use and modify.

\
